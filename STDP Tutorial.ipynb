{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will show an example of training a SNN with STDP. We will use the SNN to perform digit recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "from pygenn.genn_model import (create_custom_neuron_class, create_custom_current_source_class,\n",
    "                               create_custom_weight_update_class, GeNNModel, init_var)\n",
    "from pygenn.genn_wrapper import NO_DELAY\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the MNIST dataset for this task. You can download it here: http://yann.lecun.com/exdb/mnist/ , and you should place the files inside the `./mnist` directory. In the following cells, we will use `mlxtend` to import and examine the _training data_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/manvi/Documents/pygenn_ml_tutorial/mnist\" # change this to your path\n",
    "X, y = loadlocal_mnist(\n",
    "        images_path=path.join(data_dir, 'train-images-idx3-ubyte'),\n",
    "        labels_path=path.join(data_dir, 'train-labels-idx1-ubyte'))\n",
    "\n",
    "print(\"Loaded training images of size: \" + str(X.shape))\n",
    "print(\"Loaded training labels of size: \" + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define neuron and weight update models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start building our network, let's set up the models we will need to (a) define the behaviour of neurons and (b) specify how synapses should be updated. For (a), we use a simple integrate-and-fire (IF) neuron model. The membrane potential `V` is updated in this model by integrating the incoming current `Isyn` over time. When `V` reaches the threshold value `Vthr`, the neuron spikes and `V` is reset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_model = create_custom_neuron_class(\"if_model\",\n",
    "                param_names=[\"Vthr\"],\n",
    "                var_name_types=[(\"V\", \"scalar\"), (\"SpikeCount\", \"unsigned int\")],\n",
    "                sim_code=\"$(V) += $(Isyn) * DT;\",\n",
    "                reset_code=\n",
    "                \"\"\"\n",
    "                $(V) = 0.0;\n",
    "                $(SpikeCount)++;\n",
    "                \"\"\",\n",
    "                threshold_condition_code=\"$(V) >= $(Vthr)\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For (b), we use Additive STDP. At the time of a pre(post)-synaptic spike, the model looks at the last post(pre)-synaptic spike as this is its nearest neighbour spike of interest. It calculates `deltat`, which is the time difference between the spike (`t`) and its nearest neighbour (`sT_pre` or `sT_post`). Then, it determines the new weight `newg` by adding an exponentially decaying term based on `deltat` to the old weight. Finally, it clips this weight to stay between `gmin` and `gmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdp_model = create_custom_weight_update_class(\"stdp_model\",\n",
    "                param_names=[\"gmax\", \"taupre\", \"taupost\", \"gmin\", \"aplus\", \"aminus\"],\n",
    "                var_name_types=[(\"g\", \"scalar\")],\n",
    "                sim_code=\n",
    "                    \"\"\"\n",
    "                    $(addToInSyn, $(g));\n",
    "                    scalar deltat = $(t) - $(sT_post);\n",
    "                    if (deltat > 0) {\n",
    "                        scalar newg = $(g) - ($(aminus) * exp( - deltat / $(taupost)));\n",
    "                        $(g) = fmin($(gmax), fmax($(gmin), newg));\n",
    "                    }\n",
    "                    \"\"\",\n",
    "                learn_post_code=\n",
    "                    \"\"\"\n",
    "                    const scalar deltat = $(t) - $(sT_pre);\n",
    "                    if (deltat > 0) {\n",
    "                        scalar newg = $(g) + ($(aplus) * exp( - deltat / $(taupre)));\n",
    "                        $(g) = fmin($(gmax), fmax($(gmin), newg));\n",
    "                    }\n",
    "                    \"\"\",\n",
    "                is_pre_spike_time_required=True,\n",
    "                is_post_spike_time_required=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the simulation running, we also need a current source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_model = create_custom_current_source_class(\n",
    "                \"cs_model\",\n",
    "                var_name_types=[(\"magnitude\", \"scalar\")],\n",
    "                injection_code=\"$(injectCurrent, $(magnitude));\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should specify the values of the parameters used in the neuron and weight update models. Further, we also define some constants that we will need later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IF_PARAMS = {\"Vthr\": 5.0}\n",
    "STDP_PARAMS = {\"gmax\": 1.0,\n",
    "               \"taupre\": 4.0,\n",
    "               \"taupost\": 4.0,\n",
    "               \"gmin\": -1.0,\n",
    "               \"aplus\": 0.1,\n",
    "               \"aminus\": 0.105}\n",
    "TIMESTEP = 1.0\n",
    "PRESENT_TIMESTEPS = 100\n",
    "INPUT_CURRENT_SCALE = 1.0 / 100.0\n",
    "OUTPUT_CURRENT_SCALE = 10.0\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put the network together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're ready to build our network! Let's create the model and add some neuron populations to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GeNN model\n",
    "model = GeNNModel(\"float\", \"stdp_tutorial\")\n",
    "model.dT = TIMESTEP\n",
    "\n",
    "# Initial values for variable initialisation\n",
    "if_init = {\"V\": 0.0, \"SpikeCount\":0}\n",
    "stdp_init = {\"g\": init_var(\"Uniform\", {\"min\": STDP_PARAMS[\"gmin\"], \"max\": STDP_PARAMS[\"gmax\"]})}\n",
    "\n",
    "# Define number of neurons for each layer\n",
    "neurons_count = [784, 128, NUM_CLASSES]\n",
    "\n",
    "# Create neuron layers using the IF neuron model\n",
    "neuron_layers = []\n",
    "for i in range(len(neurons_count)):\n",
    "    neuron_layers.append(model.add_neuron_population(\"neuron%u\" % (i),\n",
    "                                                     neurons_count[i], if_model,\n",
    "                                                     IF_PARAMS, if_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add synapse populations to connect the neuron populations. We use the pretrained weights provided in this repository to initialize the weights between the first and second neuron populations. These weights will not be trained. We use `stdp_init` to initialize the weights between the second and third neuron populations. These weights will be trained using the STDP model defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained weights\n",
    "weights_0_1 = np.load(\"weights_0_1.npy\")\n",
    "\n",
    "# Create synaptic connections between layers\n",
    "synapses = []\n",
    "for i, (pre, post) in enumerate(zip(neuron_layers[:-1], neuron_layers[1:])):\n",
    "    # Use pretrained weights for connections between first two neuron populations\n",
    "    if i == 0:\n",
    "        synapses.append(model.add_synapse_population(\n",
    "            \"synapse%u\" % i, \"DENSE_INDIVIDUALG\", NO_DELAY,\n",
    "            pre, post,\n",
    "            \"StaticPulse\", {}, {\"g\": weights_0_1.flatten()}, {}, {},\n",
    "            \"DeltaCurr\", {}, {}))\n",
    "    # Use stdp_init and the STDP model for all other connections\n",
    "    else:\n",
    "        synapses.append(model.add_synapse_population(\n",
    "            \"synapse%u\" % i, \"DENSE_INDIVIDUALG\", NO_DELAY,\n",
    "            pre, post,\n",
    "            stdp_model, STDP_PARAMS, stdp_init, {}, {},\n",
    "            \"DeltaCurr\", {}, {}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also connect the current sources to the correct populations. With this, our model is ready to build and load!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create current source to deliver input to first layers of neurons\n",
    "current_input = model.add_current_source(\"current_input\", cs_model,\n",
    "                                         \"neuron0\", {}, {\"magnitude\": 0.0})\n",
    "\n",
    "# Create current source to deliver target output to last layer of neurons\n",
    "current_output = model.add_current_source(\"current_output\", cs_model,\n",
    "                                          \"neuron2\", {}, {\"magnitude\": 0.0})\n",
    "\n",
    "# Build and load our model\n",
    "model.build()\n",
    "model.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're ready to train the network! Below, we show you an example of a training procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Turn off interactive plotting for matplotlib\n",
    "plt.ioff()\n",
    "\n",
    "# Get views to efficiently access state variables\n",
    "current_input_magnitude = current_input.vars[\"magnitude\"].view\n",
    "current_output_magnitude = current_output.vars[\"magnitude\"].view\n",
    "layer_voltages = [l.vars[\"V\"].view for l in neuron_layers]\n",
    "\n",
    "# create a raster plot for every 10,000th example\n",
    "plot_example = 10\n",
    "\n",
    "# Simulate\n",
    "while model.timestep < (PRESENT_TIMESTEPS * X.shape[0]):\n",
    "    # Calculate the timestep within the presentation\n",
    "    timestep_in_example = model.timestep % PRESENT_TIMESTEPS\n",
    "    example = int(model.timestep // PRESENT_TIMESTEPS)\n",
    "\n",
    "    # If this is the first timestep of presenting the example\n",
    "    if timestep_in_example == 0:\n",
    "\n",
    "        # initialize a data structure for creating the raster plots for this example\n",
    "        layer_spikes = [(np.empty(0), np.empty(0)) for _ in enumerate(neuron_layers)]\n",
    "\n",
    "#         if example % 100 == 0:\n",
    "#             print(\"Example: \" + str(example))\n",
    "            \n",
    "        if example % 10 == 0:\n",
    "            print(\"Example: \" + str(example))\n",
    "\n",
    "        # Set the currents for the input and output layers to the desired values\n",
    "        current_input_magnitude[:] = X[example, :].flatten() * INPUT_CURRENT_SCALE\n",
    "        one_hot = np.zeros((NUM_CLASSES))\n",
    "        one_hot[y[example]] = 1\n",
    "        current_output_magnitude[:] = one_hot.flatten() * OUTPUT_CURRENT_SCALE\n",
    "        \n",
    "        model.push_var_to_device(\"current_input\", \"magnitude\")\n",
    "        model.push_var_to_device(\"current_output\", \"magnitude\")\n",
    "\n",
    "        # Loop through all layers and their corresponding voltage views\n",
    "        for l, v in zip(neuron_layers, layer_voltages):\n",
    "            # Manually 'reset' voltage\n",
    "            v[:] = 0.0\n",
    "\n",
    "            # Upload\n",
    "            model.push_var_to_device(l.name, \"V\")\n",
    "\n",
    "    # Advance simulation\n",
    "    model.step_time()\n",
    "\n",
    "    if example % plot_example == 0:\n",
    "        # populate the raster plot data structure with the spikes of this example and this timestep\n",
    "        for i, l in enumerate(neuron_layers):\n",
    "\n",
    "            # Download spikes\n",
    "            model.pull_current_spikes_from_device(l.name)\n",
    "\n",
    "            # Add to data structure\n",
    "            spike_times = np.ones_like(l.current_spikes) * model.t\n",
    "            layer_spikes[i] = (np.hstack((layer_spikes[i][0], l.current_spikes)),\n",
    "                               np.hstack((layer_spikes[i][1], spike_times)))\n",
    "\n",
    "    # If this is the LAST timestep of presenting the example\n",
    "    if timestep_in_example == (PRESENT_TIMESTEPS - 1):\n",
    "\n",
    "        # Make a plot every 10000th example\n",
    "        if example % plot_example == 0:\n",
    "\n",
    "            # Create a plot with axes for each\n",
    "            fig, axes = plt.subplots(len(neuron_layers), sharex=True)\n",
    "\n",
    "            # Loop through axes and their corresponding neuron populations\n",
    "            for a, s, l in zip(axes, layer_spikes, neuron_layers):\n",
    "                # Plot spikes\n",
    "                a.scatter(s[1], s[0], s=1)\n",
    "\n",
    "                # Set title, axis labels\n",
    "                a.set_title(l.name)\n",
    "                a.set_ylabel(\"Spike number\")\n",
    "                a.set_xlim((example * PRESENT_TIMESTEPS, (example + 1) * PRESENT_TIMESTEPS))\n",
    "                a.set_ylim((-1, l.size + 1))\n",
    "\n",
    "\n",
    "            # Add an x-axis label\n",
    "            axes[-1].set_xlabel(\"Time [ms]\")\n",
    "\n",
    "            # Show plot\n",
    "            save_filename = 'example' + str(example) + '.png'\n",
    "            plt.savefig(save_filename)\n",
    "\n",
    "\n",
    "print(\"Completed training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the weights of the network, so we can use them later for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, l in enumerate(synapses):\n",
    "\n",
    "    model.pull_var_from_device(l.name, \"g\")\n",
    "    weight_values = l.get_var_values(\"g\")\n",
    "    np.save(\"w_\"+str(i)+\"_\"+str(i+1)+\".npy\", weight_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the _testing data_ and the weights we just trained to assess how well we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = loadlocal_mnist(\n",
    "        images_path=path.join(data_dir, 't10k-images-idx3-ubyte'),\n",
    "        labels_path=path.join(data_dir, 't10k-labels-idx1-ubyte'))\n",
    "\n",
    "print(\"Loaded testing images of size: \" + str(X.shape))\n",
    "print(\"Loaded testing labels of size: \" + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing, we will use the IF neurons and the same network architecture as before, but we will not use the STDP weight update model. Instead, we will use static synapses. But first, let's import our trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "while True:\n",
    "    filename = \"w_%u_%u.npy\" % (len(weights), len(weights) + 1)\n",
    "    if path.exists(filename):\n",
    "        print(\"Loading weights from: \" + str(filename))\n",
    "        weights.append(np.load(filename))\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's set up our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "model = GeNNModel(\"float\", \"stdp_tutorial\")\n",
    "model.dT = TIMESTEP\n",
    "\n",
    "# Initial values to initialize all neurons\n",
    "if_init = {\"V\": 0.0, \"SpikeCount\":0}\n",
    "\n",
    "# Create neuron layers\n",
    "neurons_count = [784, 128, NUM_CLASSES]\n",
    "neuron_layers = []\n",
    "\n",
    "for i in range(len(neurons_count)):\n",
    "    neuron_layers.append(model.add_neuron_population(\"neuron%u\" % (i),\n",
    "                                                     neurons_count[i], if_model,\n",
    "                                                     IF_PARAMS, if_init))\n",
    "\n",
    "# Create synapses between layers\n",
    "for i, (pre, post, w) in enumerate(zip(neuron_layers[:-1], neuron_layers[1:], weights)):\n",
    "    model.add_synapse_population(\n",
    "        \"synapse%u\" % i, \"DENSE_INDIVIDUALG\", NO_DELAY,\n",
    "        pre, post,\n",
    "        \"StaticPulse\", {}, {\"g\": w.flatten()}, {}, {},\n",
    "        \"DeltaCurr\", {}, {})\n",
    "\n",
    "# Create current source to deliver input to first layer of neurons\n",
    "current_input = model.add_current_source(\"current_input\", cs_model,\n",
    "                                         \"neuron0\" , {}, {\"magnitude\": 0.0})\n",
    "\n",
    "# Build and load model\n",
    "model.build()\n",
    "model.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're ready to test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = 0\n",
    "\n",
    "current_input_magnitude = current_input.vars[\"magnitude\"].view\n",
    "output_spike_count = neuron_layers[-1].vars[\"SpikeCount\"].view\n",
    "layer_voltages = [l.vars[\"V\"].view for l in neuron_layers]\n",
    "\n",
    "while model.timestep < (PRESENT_TIMESTEPS * X.shape[0]):\n",
    "    # Calculate the timestep within the presentation\n",
    "    timestep_in_example = model.timestep % PRESENT_TIMESTEPS\n",
    "    example = int(model.timestep // PRESENT_TIMESTEPS)\n",
    "\n",
    "    # If this is the first timestep of presenting the example\n",
    "    if timestep_in_example == 0:\n",
    "        current_input_magnitude[:] = X[example] * INPUT_CURRENT_SCALE\n",
    "        model.push_var_to_device(\"current_input\", \"magnitude\")\n",
    "\n",
    "        # Loop through all layers and their corresponding voltage views\n",
    "        for l, v in zip(neuron_layers, layer_voltages):\n",
    "            # Manually 'reset' voltage\n",
    "            v[:] = 0.0\n",
    "\n",
    "            # Upload\n",
    "            model.push_var_to_device(l.name, \"V\")\n",
    "\n",
    "        # Zero spike count\n",
    "        output_spike_count[:] = 0\n",
    "        model.push_var_to_device(neuron_layers[-1].name, \"SpikeCount\")\n",
    "\n",
    "    # Advance simulation\n",
    "    model.step_time()\n",
    "\n",
    "    # If this is the LAST timestep of presenting the example\n",
    "    if timestep_in_example == (PRESENT_TIMESTEPS - 1):\n",
    "        # Download spike count from last layer\n",
    "        model.pull_var_from_device(neuron_layers[-1].name, \"SpikeCount\")\n",
    "\n",
    "        # Find which neuron spiked the most to get prediction\n",
    "        predicted_label = np.argmax(output_spike_count)\n",
    "        true_label = y[example]\n",
    "\n",
    "        print(\"\\tExample=%u, true label=%u, predicted label=%u\" % (example,\n",
    "                                                                   true_label,\n",
    "                                                                   predicted_label))\n",
    "\n",
    "        if predicted_label == true_label:\n",
    "            num_correct += 1\n",
    "\n",
    "print(\"Accuracy %f%%\" % ((num_correct / float(y.shape[0])) * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also change this task to be a binary (only differentiate between `0` and `1`) or a one-vs-all (differentiate between one digit and all the others) task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources:\n",
    "\n",
    "The code presented in this tutorial was adapted from:\n",
    "1. https://github.com/neworderofjamie/pygenn_ml_tutorial\n",
    "2. https://github.com/neworderofjamie/genn_examples/blob/master/common/stdp_additive.h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
